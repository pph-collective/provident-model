{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVIDENT: Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import scipy\n",
    "import sklearn\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the desired datasets\n",
    "ems = pd.read_csv(\"filepath\\\\ems.csv\")\n",
    "pdmp = pd.read_csv(\"filepath\\\\pdmp.csv\")\n",
    "acs = pd.read_csv(\"filepath\\\\acs.csv\")\n",
    "rigis = pd.read_csv(\"filepath\\\\rigis.csv\")\n",
    "od = pd.read_csv(\"filepath\\\\sudors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_varying = pd.merge(pdmp,ems, on='GEOID')\n",
    "time_varying.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fixed = pd.merge(acs,rigis, on='GEOID')\n",
    "time_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_fixed.shape)\n",
    "print(time_varying.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.rename(columns={'municipality': 'TOWN'})\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run these chunks to format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing the \"ground truth\" rankings for MSE and R2\n",
    "ground_truth_20200 = od['2020_1']\n",
    "ground_truth_20195 = od['2019_2']\n",
    "ground_truth_20190 = od['2019_1']\n",
    "ground_truth_20185 = od['2018_2']\n",
    "ground_truth_20180 = od['2018_1']\n",
    "ground_truth_20175 = od['2017_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODELING APPROACH\n",
    "# Training:\n",
    "# (1) Predict 2020.1 (t) given 2019.2 (t-1) and 2019.1 (t-2) AND\n",
    "# (2) Predict 2019.2 (t) given 2019.1 (t-1) and 2018.2 (t-2) AND\n",
    "# (3) Predict 2019.1 (t) given 2018.2 (t-1) and 2018.1 (t-2) AND\n",
    "# (4) Predict 2018.2 (t) given 2018.1 (t-1) and 2017.2 (t-2) AND\n",
    "# (5) Predict 2018.1 (t) given 2017.2 (t-1) and 2017.1 (t-2) AND\n",
    "# (6) Predict 2017.2 (t) given 2017.1 (t-1) and 2016.2 (t-2) AND\n",
    "# (7) Predict 2017.1 (t) given 2016.2 (t-1) and 2016.1 (t-2)\n",
    "#\n",
    "# Test: (1) Predict 2020.1 (t) given 2019.2 (t-1) and 2019.1 (t-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the moving windows with time-varying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the column suffixes for training set X\n",
    "# FOR TIME VARYING COMBINED PDMP+EMS\n",
    "x_train_varying_11 = time_varying.columns[time_varying.columns.str.contains('_2019_2')]\n",
    "x_train_varying_12 = time_varying.columns[time_varying.columns.str.contains('_2019_1')]\n",
    "x_train_varying_21 = time_varying.columns[time_varying.columns.str.contains('_2019_1')]\n",
    "x_train_varying_22 = time_varying.columns[time_varying.columns.str.contains('_2018_2')]\n",
    "x_train_varying_31 = time_varying.columns[time_varying.columns.str.contains('_2018_2')]\n",
    "x_train_varying_32 = time_varying.columns[time_varying.columns.str.contains('_2018_1')]\n",
    "x_train_varying_41 = time_varying.columns[time_varying.columns.str.contains('_2018_1')]\n",
    "x_train_varying_42 = time_varying.columns[time_varying.columns.str.contains('_2017_2')]\n",
    "x_train_varying_51 = time_varying.columns[time_varying.columns.str.contains('_2017_2')]\n",
    "x_train_varying_52 = time_varying.columns[time_varying.columns.str.contains('_2017_1')]\n",
    "x_train_varying_61 = time_varying.columns[time_varying.columns.str.contains('_2017_1')]\n",
    "x_train_varying_62 = time_varying.columns[time_varying.columns.str.contains('_2016_2')]\n",
    "x_train_varying_71 = time_varying.columns[time_varying.columns.str.contains('_2016_2')]\n",
    "x_train_varying_72 = time_varying.columns[time_varying.columns.str.contains('_2016_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TIME VARYING COMBINED PDMP+EMS\n",
    "x_train_11 = time_varying.loc[:,x_train_varying_11]\n",
    "x_train_12 = time_varying.loc[:,x_train_varying_12]\n",
    "x_train_21 = time_varying.loc[:,x_train_varying_21]\n",
    "x_train_22 = time_varying.loc[:,x_train_varying_22]\n",
    "x_train_31 = time_varying.loc[:,x_train_varying_31]\n",
    "x_train_32 = time_varying.loc[:,x_train_varying_32]\n",
    "x_train_41 = time_varying.loc[:,x_train_varying_41]\n",
    "x_train_42 = time_varying.loc[:,x_train_varying_42]\n",
    "x_train_51 = time_varying.loc[:,x_train_varying_51]\n",
    "x_train_52 = time_varying.loc[:,x_train_varying_52]\n",
    "x_train_61 = time_varying.loc[:,x_train_varying_61]\n",
    "x_train_62 = time_varying.loc[:,x_train_varying_62]\n",
    "x_train_71 = time_varying.loc[:,x_train_varying_71]\n",
    "x_train_72 = time_varying.loc[:,x_train_varying_72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_11.columns = x_train_11.columns.str.replace('2019_2', 't-1')\n",
    "x_train_12.columns = x_train_12.columns.str.replace('2019_1', 't-2')\n",
    "x_train_21.columns = x_train_21.columns.str.replace('2019_1', 't-1')\n",
    "x_train_22.columns = x_train_22.columns.str.replace('2018_2', 't-2')\n",
    "x_train_31.columns = x_train_31.columns.str.replace('2018_2', 't-1')\n",
    "x_train_32.columns = x_train_32.columns.str.replace('2018_1', 't-2')\n",
    "x_train_41.columns = x_train_41.columns.str.replace('2018_1', 't-1')\n",
    "x_train_42.columns = x_train_42.columns.str.replace('2017_2', 't-2')\n",
    "x_train_51.columns = x_train_51.columns.str.replace('2017_2', 't-1')\n",
    "x_train_52.columns = x_train_52.columns.str.replace('2017_1', 't-2')\n",
    "x_train_61.columns = x_train_61.columns.str.replace('2017_1', 't-1')\n",
    "x_train_62.columns = x_train_62.columns.str.replace('2016_2', 't-2')\n",
    "x_train_71.columns = x_train_71.columns.str.replace('2016_2', 't-1')\n",
    "x_train_72.columns = x_train_72.columns.str.replace('2016_1', 't-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = pd.concat([x_train_11,x_train_12],axis=1)\n",
    "x_train_2 = pd.concat([x_train_21,x_train_22],axis=1)\n",
    "x_train_3 = pd.concat([x_train_31,x_train_32],axis=1)\n",
    "x_train_4 = pd.concat([x_train_41,x_train_42],axis=1)\n",
    "x_train_5 = pd.concat([x_train_51,x_train_52],axis=1)\n",
    "x_train_6 = pd.concat([x_train_61,x_train_62],axis=1)\n",
    "x_train_7 = pd.concat([x_train_71,x_train_72],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_varying_a = pd.concat([x_train_1,x_train_2])\n",
    "x_train_varying_b = pd.concat([x_train_varying_a,x_train_3])\n",
    "x_train_varying_c = pd.concat([x_train_varying_b,x_train_4])\n",
    "x_train_varying_d = pd.concat([x_train_varying_c,x_train_5])\n",
    "x_train_varying_e = pd.concat([x_train_varying_d,x_train_6])\n",
    "x_train_varying = pd.concat([x_train_varying_e,x_train_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_varying.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_varying.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the moving windows with time-fixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_fixed = time_fixed.loc[:,'var_name':'var_name']\n",
    "rigis_fixed = time_fixed.loc[:,'var_name':'var_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fixed = pd.concat([acs_fixed,rigis_fixed],axis=1)\n",
    "time_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fixed_a = pd.concat([time_fixed,time_fixed])\n",
    "x_train_fixed_b = pd.concat([x_train_fixed_a,time_fixed])\n",
    "x_train_fixed_c = pd.concat([x_train_fixed_b,time_fixed])\n",
    "x_train_fixed_d = pd.concat([x_train_fixed_c,time_fixed])\n",
    "x_train_fixed_e = pd.concat([x_train_fixed_d,time_fixed])\n",
    "x_train_fixed = pd.concat([x_train_fixed_e,time_fixed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_od1 = od[['2019_2','2019_1']]\n",
    "x_train_od2 = od[['2019_1','2018_2']]\n",
    "x_train_od3 = od[['2018_2','2018_1']]\n",
    "x_train_od4 = od[['2018_1','2017_2']]\n",
    "x_train_od5 = od[['2017_2','2017_1']]\n",
    "x_train_od6 = od[['2017_1','2016_2']]\n",
    "x_train_od7 = od[['2016_2','2016_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_od1.columns = x_train_od1.columns.str.replace('2019_2', 't-1')\n",
    "x_train_od1.columns = x_train_od1.columns.str.replace('2019_1', 't-2')\n",
    "x_train_od2.columns = x_train_od2.columns.str.replace('2019_1', 't-1')\n",
    "x_train_od2.columns = x_train_od2.columns.str.replace('2018_2', 't-2')\n",
    "x_train_od3.columns = x_train_od3.columns.str.replace('2018_2', 't-1')\n",
    "x_train_od3.columns = x_train_od3.columns.str.replace('2018_1', 't-2')\n",
    "x_train_od4.columns = x_train_od4.columns.str.replace('2018_1', 't-1')\n",
    "x_train_od4.columns = x_train_od4.columns.str.replace('2017_2', 't-2')\n",
    "x_train_od5.columns = x_train_od5.columns.str.replace('2017_2', 't-1')\n",
    "x_train_od5.columns = x_train_od5.columns.str.replace('2017_1', 't-2')\n",
    "x_train_od6.columns = x_train_od6.columns.str.replace('2017_1', 't-1')\n",
    "x_train_od6.columns = x_train_od6.columns.str.replace('2016_2', 't-2')\n",
    "x_train_od7.columns = x_train_od7.columns.str.replace('2016_2', 't-1')\n",
    "x_train_od7.columns = x_train_od7.columns.str.replace('2016_1', 't-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_od_a = pd.concat([x_train_od1,x_train_od2])\n",
    "x_train_od_b = pd.concat([x_train_od_a,x_train_od3])\n",
    "x_train_od_c = pd.concat([x_train_od_b,x_train_od4])\n",
    "x_train_od_d = pd.concat([x_train_od_c,x_train_od5])\n",
    "x_train_od_e = pd.concat([x_train_od_d,x_train_od6])\n",
    "x_train_od = pd.concat([x_train_od_e,x_train_od7])\n",
    "x_train_od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_fixed.shape)\n",
    "print(x_train_varying.shape)\n",
    "print(x_train_od.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = pd.concat([x_train_fixed,x_train_varying],axis=1)\n",
    "x_train = pd.concat([x_train_a,x_train_od],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = od[['2020_1']]\n",
    "y_train1.columns = ['t']\n",
    "y_train2 = od[['2019_2']]\n",
    "y_train2.columns = ['t']\n",
    "y_train3 = od[['2019_1']]\n",
    "y_train3.columns = ['t']\n",
    "y_train4 = od[['2018_2']]\n",
    "y_train4.columns = ['t']\n",
    "y_train5 = od[['2018_1']]\n",
    "y_train5.columns = ['t']\n",
    "y_train6 = od[['2017_2']]\n",
    "y_train6.columns = ['t']\n",
    "y_train7 = od[['2017_1']]\n",
    "y_train7.columns = ['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_a = pd.concat([y_train1,y_train2])\n",
    "y_train_b = pd.concat([y_train_a,y_train3])\n",
    "y_train_c = pd.concat([y_train_b,y_train4])\n",
    "y_train_d = pd.concat([y_train_c,y_train5])\n",
    "y_train_e = pd.concat([y_train_d,y_train6])\n",
    "y_train = pd.concat([y_train_e,y_train7])\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: (1) Predict 2020.2 (FUTURE) (t) given 2020.1 (t-1) and 2019.2 (t-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the column suffixes for test set X\n",
    "x_test_varying_1 = time_varying.columns[time_varying.columns.str.contains('_2020_1')]\n",
    "x_test_varying_2 = time_varying.columns[time_varying.columns.str.contains('_2019_2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the columns for test set X\n",
    "x_test_varying1 = time_varying.loc[:,x_test_varying_1]\n",
    "x_test_varying2 = time_varying.loc[:,x_test_varying_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_varying1.columns = x_test_varying1.columns.str.replace('2020_1', 't-1')\n",
    "x_test_varying2.columns = x_test_varying2.columns.str.replace('2019_2', 't-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_varying = pd.concat([x_test_varying1,x_test_varying2],axis=1)\n",
    "x_test_varying.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_od = od[['2020_1','2019_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_od.columns = x_test_od.columns.str.replace('2020_1', 't-1')\n",
    "x_test_od.columns = x_test_od.columns.str.replace('2019_2', 't-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_fixed.shape)\n",
    "print(x_test_varying.shape)\n",
    "print(x_test_od.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a = pd.concat([time_fixed,x_test_varying],axis=1)\n",
    "x_test = pd.concat([x_test_a,x_test_od],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO Y TEST BECAUSE WE ARE PREDICTING THE FUTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = pd.DataFrame(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled.columns = x_train.columns\n",
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "en = ElasticNetCV(max_iter=10000,tol=0.008)\n",
    "sel_ = en.fit(x_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ = SelectFromModel(estimator=ElasticNetCV(max_iter=10000,tol=0.008))\n",
    "sel_.fit(x_train_scaled,y_train.values.ravel())\n",
    "sel_.get_support()\n",
    "x_train_selected = pd.DataFrame(x_train, columns = x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats = x_train_selected.columns[(sel_.get_support())]\n",
    "print('Total features: {}'.format((x_train_scaled.shape[1])))\n",
    "print('Selected features: {}'.format(len(selected_feats)))\n",
    "print('Features with coef at 0: {}'.format(np.sum(sel_.estimator_.coef_==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_feats = x_train.columns[(sel_.estimator_.coef_==0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_selected = sel_.transform(x_train)\n",
    "x_test_selected = sel_.transform(x_test)\n",
    "print(x_test_selected.shape)\n",
    "print(x_train_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest and sci-kit GBM\n",
    "param_grid = {'max_depth':range(1,9,1), 'min_samples_leaf':[1,2,5,10,20,50,100], 'max_features':[0.33,'auto'], 'n_estimators':range(50,300,50)}\n",
    "gb = GradientBoostingRegressor(random_state=888)\n",
    "gs = GridSearchCV(gb,param_grid=param_grid,cv=5)\n",
    "rs = gs.fit(x_train_selected,y_train.values.ravel())\n",
    "print(rs.best_params_)\n",
    "print(rs.score(x_train_selected,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining predictions for the validation and test sets\n",
    "sudors['FINAL'] = rs.predict(x_test_selected)\n",
    "sudors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
